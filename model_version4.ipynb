{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f0ee54a",
   "metadata": {},
   "source": [
    "# GPT-2 & ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264c834b",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c8cbe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "class SurgicalVQADataset(Dataset):\n",
    "    def __init__(self, seq, folder_head, folder_tail, labels, transform=None):\n",
    "        \n",
    "        self.transform = transform\n",
    "        \n",
    "        # files, question and answers\n",
    "        filenames = []\n",
    "        for curr_seq in seq: filenames = filenames + glob.glob(folder_head + str(curr_seq) + folder_tail)\n",
    "        self.vqas = []\n",
    "        for file in filenames:\n",
    "            file_data = open(file, \"r\")\n",
    "            lines = [line.strip(\"\\n\") for line in file_data if line != \"\\n\"]\n",
    "            file_data.close()\n",
    "            for line in lines: self.vqas.append([file, line])\n",
    "        print('Total files: %d | Total question: %.d' %(len(filenames), len(self.vqas)))\n",
    "        \n",
    "        # Labels\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.vqas)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # img\n",
    "        loc = self.vqas[idx][0].split('/')\n",
    "        img_loc = os.path.join(loc[0],loc[1],loc[2], 'left_frames',loc[-1].split('_')[0]+'.png')\n",
    "        img = Image.open(img_loc)\n",
    "        if self.transform: img = self.transform(img)\n",
    "            \n",
    "        # question and answer\n",
    "        question = self.vqas[idx][1].split('|')[0]\n",
    "        label = self.labels.index(str(self.vqas[idx][1].split('|')[1]))\n",
    "\n",
    "        return img, question, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a6e890",
   "metadata": {},
   "source": [
    "## Model Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d710b349",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "class Surgical_VQA(nn.Module):\n",
    "    def __init__(self, num_classes=12):\n",
    "        super(Surgical_VQA, self).__init__()\n",
    "\n",
    "        # text processing\n",
    "        self.text_feature_extractor = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "        # image processing\n",
    "        self.img_feature_extractor = models.resnet50(pretrained=True)\n",
    "        new_fc = nn.Sequential(*list(self.img_feature_extractor.fc.children())[:-1])\n",
    "        self.img_feature_extractor.fc = new_fc\n",
    "\n",
    "        #classifier\n",
    "        self.classifier = nn.Linear(2816, num_classes)\n",
    "\n",
    "    def forward(self, img, text):\n",
    "        img_feature = self.img_feature_extractor(img)\n",
    "        \n",
    "        text_feature = self.text_feature_extractor.encode(text)\n",
    "        text_feature = torch.tensor(text_feature).cuda()\n",
    "        \n",
    "        img_text_features = torch.cat((img_feature, text_feature), dim=1)\n",
    "        \n",
    "        out = self.classifier(img_text_features)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a85e42",
   "metadata": {},
   "source": [
    "## Model Version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63597038",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "class Surgical_VQA(nn.Module):\n",
    "    def __init__(self, num_classes=12):\n",
    "        super(Surgical_VQA, self).__init__()\n",
    "\n",
    "        # text processing\n",
    "        self.text_feature_extractor = SentenceTransformer('bert-large-nli-mean-tokens')\n",
    "        # image processing\n",
    "        self.img_feature_extractor = models.resnet50(pretrained=True)\n",
    "        new_fc = nn.Sequential(*list(self.img_feature_extractor.fc.children())[:-1])\n",
    "        self.img_feature_extractor.fc = new_fc\n",
    "\n",
    "        #classifier\n",
    "        self.classifier = nn.Linear(3072, num_classes)\n",
    "\n",
    "    def forward(self, img, text):\n",
    "        img_feature = self.img_feature_extractor(img)\n",
    "        \n",
    "        text_feature = self.text_feature_extractor.encode(text)\n",
    "        text_feature = torch.tensor(text_feature).cuda()\n",
    "        \n",
    "        img_text_features = torch.cat((img_feature, text_feature), dim=1)\n",
    "        \n",
    "        out = self.classifier(img_text_features)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d0dabd",
   "metadata": {},
   "source": [
    "## Model Version 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "539b53ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/mobarak/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from InferSent.models import InferSent\n",
    "\n",
    "class Surgical_VQA(nn.Module):\n",
    "    def __init__(self, num_classes=12):\n",
    "        super(Surgical_VQA, self).__init__()\n",
    "\n",
    "        # text processing\n",
    "        params_model = {'bsize': 64, 'word_emb_dim': 300, 'enc_lstm_dim': 2048,\n",
    "                        'pool_type': 'max', 'dpout_model': 0.0, 'version': 2}\n",
    "        self.text_feature_extractor = InferSent(params_model)\n",
    "        self.text_feature_extractor.load_state_dict(torch.load('InferSent/encoder/infersent2.pkl'))\n",
    "        self.text_feature_extractor.set_w2v_path('InferSent/fastText/crawl-300d-2M.vec')\n",
    "        self.text_feature_extractor.build_vocab_k_words(K=100000)\n",
    "        \n",
    "        # image processing\n",
    "        self.img_feature_extractor = models.resnet50(pretrained=True)\n",
    "        new_fc = nn.Sequential(*list(self.img_feature_extractor.fc.children())[:-1])\n",
    "        self.img_feature_extractor.fc = new_fc\n",
    "\n",
    "        #classifier\n",
    "        self.classifier = nn.Linear(6144, num_classes)\n",
    "\n",
    "    def forward(self, img, text):\n",
    "        img_feature = self.img_feature_extractor(img)\n",
    "        \n",
    "        text_feature = self.text_feature_extractor.encode(text) #infersent.encode(query)[0]\n",
    "        text_feature = torch.tensor(text_feature).cuda()\n",
    "        \n",
    "        img_text_features = torch.cat((img_feature, text_feature), dim=1)\n",
    "        \n",
    "        out = self.classifier(img_text_features)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32705a13",
   "metadata": {},
   "source": [
    "## Model Version 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1467f52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "\n",
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "\n",
    "\n",
    "class Surgical_VQA(nn.Module):\n",
    "    def __init__(self, num_classes=12):\n",
    "        super(Surgical_VQA, self).__init__()\n",
    "\n",
    "        # text processing\n",
    "        self.tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        self.text_feature_extractor = GPT2Model.from_pretrained('gpt2')\n",
    " \n",
    "        # image processing\n",
    "        self.img_feature_extractor = models.resnet50(pretrained=True)\n",
    "        new_fc = nn.Sequential(*list(self.img_feature_extractor.fc.children())[:-1])\n",
    "        self.img_feature_extractor.fc = new_fc\n",
    "\n",
    "        #classifier\n",
    "        self.classifier = nn.Linear(2816, num_classes)\n",
    "\n",
    "    def forward(self, img, text):\n",
    "        \n",
    "        # image\n",
    "        img_feature = self.img_feature_extractor(img)\n",
    "        \n",
    "        # text\n",
    "        encoded_text = self.tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        encoded_text['input_ids'] = encoded_text['input_ids'].cuda()\n",
    "        encoded_text['attention_mask'] = encoded_text['attention_mask'].cuda()\n",
    "        text_feature = self.text_feature_extractor(**encoded_text)\n",
    "        text_feature = text_feature.last_hidden_state.swapaxes(1,2)\n",
    "        text_feature = F.adaptive_avg_pool1d(text_feature,1)\n",
    "        text_feature = text_feature.swapaxes(1,2).squeeze(1)        \n",
    "        img_text_features = torch.cat((img_feature, text_feature), dim=1)\n",
    "        \n",
    "        out = self.classifier(img_text_features)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd2e3b3",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8eef33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "def calc_acc(y_true, y_pred):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    return acc\n",
    "\n",
    "def calc_classwise_acc(y_true, y_pred):\n",
    "    matrix = confusion_matrix(y_true, y_pred)\n",
    "    classwise_acc = matrix.diagonal()/matrix.sum(axis=1)\n",
    "    return classwise_acc\n",
    "\n",
    "def calc_map(y_true, y_scores):\n",
    "    mAP = average_precision_score(y_true, y_scores,average=None)\n",
    "    return mAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23248629",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f25b694e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def test_model(epoch, model, valid_dataloader):\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0.0    \n",
    "    label_true = None\n",
    "    label_pred = None\n",
    "    label_score = None\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (imgs, q, labels) in enumerate(valid_dataloader, 0):\n",
    "            questions = []\n",
    "            for question in q: questions.append(question)\n",
    "            imgs, labels = imgs.cuda(), labels.cuda()\n",
    "            \n",
    "            outputs = model(imgs, questions)\n",
    "\n",
    "            loss = criterion(outputs,labels)\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "            scores, predicted = torch.max(F.softmax(outputs, dim=1).data, 1)    \n",
    "            label_true = labels.data.cpu() if label_true == None else torch.cat((label_true, labels.data.cpu()), 0)\n",
    "            label_pred = predicted.data.cpu() if label_pred == None else torch.cat((label_pred, predicted.data.cpu()), 0)\n",
    "            label_score = scores.data.cpu() if label_score == None else torch.cat((label_score, scores.data.cpu()), 0)\n",
    "\n",
    "            \n",
    "    acc, c_acc, mAP = calc_acc(label_true, label_pred), calc_classwise_acc(label_true, label_pred), 0.0#calc_map(label_true, label_score)\n",
    "\n",
    "    print('Test: epoch: %d loss: %.6f | Acc: %.6f | mAP: %.6f' %(epoch, total_loss, acc, mAP))\n",
    "    print(c_acc)\n",
    "    \n",
    "    return (acc, c_acc, mAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c11ee3",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dccb841",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "def train_model(epoch, model, train_dataloader, lr):  # train model\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    total_loss = 0.0    \n",
    "    label_true = None\n",
    "    label_pred = None\n",
    "    label_score = None\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr = lr, weight_decay = 0)\n",
    "    \n",
    "    for i, (imgs, q, labels) in enumerate(train_dataloader,0):\n",
    "        questions = []\n",
    "        for question in q: questions.append(question)\n",
    "        imgs, labels = imgs.cuda(), labels.cuda()\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(imgs, questions)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        scores, predicted = torch.max(F.softmax(outputs, dim=1).data, 1)    \n",
    "        label_true = labels.data.cpu() if label_true == None else torch.cat((label_true, labels.data.cpu()), 0)\n",
    "        label_pred = predicted.data.cpu() if label_pred == None else torch.cat((label_pred, predicted.data.cpu()), 0)\n",
    "        label_score = scores.data.cpu() if label_score == None else torch.cat((label_score, scores.data.cpu()), 0)\n",
    "\n",
    "    \n",
    "    # loss and acc\n",
    "    acc, c_acc, mAP = calc_acc(label_true, label_pred), calc_classwise_acc(label_true, label_pred), 0.0#calc_map(label_true, label_score)\n",
    "\n",
    "    print('Train: epoch: %d loss: %.6f | Acc: %.6f | mAP: %.6f' %(epoch, total_loss, acc, mAP))\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f2d921",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4154d89f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files: 1560 | Total question: 9014\n",
      "Total files: 447 | Total question: 2769\n",
      "Train: epoch: 1 loss: 422.574315 | Acc: 0.564566 | mAP: 0.000000\n",
      "Test: epoch: 1 loss: 219.202679 | Acc: 0.758487 | mAP: 0.000000\n",
      "[1.         0.90981109 0.         0.79790026 0.69448373 0.\n",
      " 0.51966874 0.         0.         0.2601626  0.         0.\n",
      " 0.         0.         0.82813537 0.76112026 0.57815443 0.47789474]\n",
      "Best epoch: 1 | Best acc: 0.758487\n",
      "Train: epoch: 2 loss: 204.987015 | Acc: 0.760484 | mAP: 0.000000\n",
      "Test: epoch: 2 loss: 155.270176 | Acc: 0.813623 | mAP: 0.000000\n",
      "[1.         0.86532602 0.         0.89501312 0.67892504 0.34375\n",
      " 0.99378882 0.         0.         0.64227642 0.         0.\n",
      " 0.         0.59722222 0.84140677 0.77182867 0.56685499 0.80210526]\n",
      "Best epoch: 2 | Best acc: 0.813623\n",
      "Train: epoch: 3 loss: 158.492421 | Acc: 0.809629 | mAP: 0.000000\n",
      "Test: epoch: 3 loss: 126.301651 | Acc: 0.855891 | mAP: 0.000000\n",
      "[1.         0.83729433 0.         0.95275591 0.73833098 0.484375\n",
      " 0.99378882 0.         1.         0.91869919 0.         0.\n",
      " 0.         0.94444444 0.86927671 0.86985173 0.64595104 0.85052632]\n",
      "Best epoch: 3 | Best acc: 0.855891\n",
      "Train: epoch: 4 loss: 136.171883 | Acc: 0.839583 | mAP: 0.000000\n",
      "Test: epoch: 4 loss: 104.467949 | Acc: 0.886732 | mAP: 0.000000\n",
      "[1.         0.87629494 0.         0.94225722 0.79632249 0.4765625\n",
      " 0.99378882 0.         1.         0.99186992 0.         0.36585366\n",
      " 0.         0.95833333 0.93297943 0.87397035 0.70809793 0.89052632]\n",
      "Best epoch: 4 | Best acc: 0.886732\n",
      "Train: epoch: 5 loss: 119.650129 | Acc: 0.863657 | mAP: 0.000000\n",
      "Test: epoch: 5 loss: 93.451785 | Acc: 0.907366 | mAP: 0.000000\n",
      "[1.         0.87995125 0.         0.97900262 0.84441301 0.546875\n",
      " 0.99792961 0.         1.         0.97560976 0.         1.\n",
      " 0.         1.         0.88918381 0.90609555 0.90207156 0.92842105]\n",
      "Best epoch: 5 | Best acc: 0.907366\n",
      "Train: epoch: 6 loss: 110.720745 | Acc: 0.873530 | mAP: 0.000000\n",
      "Test: epoch: 6 loss: 83.470749 | Acc: 0.914355 | mAP: 0.000000\n",
      "[1.         0.90981109 0.         0.97637795 0.8175389  0.5625\n",
      " 0.99171843 0.         0.98333333 0.99186992 0.         1.\n",
      " 0.61538462 1.         0.94094227 0.87314662 0.89077213 0.91578947]\n",
      "Best epoch: 6 | Best acc: 0.914355\n",
      "Train: epoch: 7 loss: 99.981413 | Acc: 0.890393 | mAP: 0.000000\n",
      "Test: epoch: 7 loss: 77.863531 | Acc: 0.920568 | mAP: 0.000000\n",
      "[1.         0.90737355 0.         0.97375328 0.82602546 0.6484375\n",
      " 0.99171843 0.30769231 1.         1.         0.         1.\n",
      " 0.61538462 0.98611111 0.90510949 0.91103789 0.95291902 0.94526316]\n",
      "Best epoch: 7 | Best acc: 0.920568\n",
      "Train: epoch: 8 loss: 93.504760 | Acc: 0.894276 | mAP: 0.000000\n",
      "Test: epoch: 8 loss: 71.999358 | Acc: 0.926559 | mAP: 0.000000\n",
      "[1.         0.91468617 0.25423729 0.98425197 0.87835926 0.5625\n",
      " 0.99792961 0.69230769 0.96666667 0.97560976 0.         1.\n",
      " 0.61538462 1.         0.93961513 0.90527183 0.83804143 0.96421053]\n",
      "Best epoch: 8 | Best acc: 0.926559\n",
      "Train: epoch: 9 loss: 86.989882 | Acc: 0.904260 | mAP: 0.000000\n",
      "Test: epoch: 9 loss: 67.519746 | Acc: 0.928223 | mAP: 0.000000\n",
      "[1.         0.89152956 0.25423729 0.97900262 0.87411598 0.8515625\n",
      " 1.         0.69230769 0.98333333 0.99186992 0.         1.\n",
      " 0.92307692 1.         0.91572661 0.89456343 0.96798493 0.94947368]\n",
      "Best epoch: 9 | Best acc: 0.928223\n",
      "Train: epoch: 10 loss: 84.342332 | Acc: 0.910473 | mAP: 0.000000\n",
      "Test: epoch: 10 loss: 62.969005 | Acc: 0.938540 | mAP: 0.000000\n",
      "[1.         0.87141987 0.54237288 0.98425197 0.91796322 0.96875\n",
      " 1.         0.69230769 1.         0.97560976 0.         1.\n",
      " 1.         1.         0.94094227 0.91515651 0.94350282 0.97263158]\n",
      "Best epoch: 10 | Best acc: 0.938540\n",
      "Train: epoch: 11 loss: 80.357866 | Acc: 0.913468 | mAP: 0.000000\n",
      "Test: epoch: 11 loss: 61.252853 | Acc: 0.933215 | mAP: 0.000000\n",
      "[1.         0.87507617 0.72881356 0.98687664 0.91089109 0.890625\n",
      " 1.         0.69230769 1.         1.         0.5        1.\n",
      " 0.84615385 1.         0.94226941 0.90197694 0.88700565 0.94947368]\n",
      "Best epoch: 10 | Best acc: 0.938540\n",
      "Train: epoch: 12 loss: 76.052749 | Acc: 0.917684 | mAP: 0.000000\n",
      "Test: epoch: 12 loss: 57.859736 | Acc: 0.942978 | mAP: 0.000000\n",
      "[1.         0.94332724 0.81355932 0.98687664 0.82885431 0.7421875\n",
      " 1.         0.84615385 1.         0.95121951 0.33333333 1.\n",
      " 1.         1.         0.93497014 0.92092257 0.93973635 0.97263158]\n",
      "Best epoch: 12 | Best acc: 0.942978\n",
      "Train: epoch: 13 loss: 71.955472 | Acc: 0.922565 | mAP: 0.000000\n",
      "Test: epoch: 13 loss: 55.379889 | Acc: 0.944087 | mAP: 0.000000\n",
      "[1.         0.91712371 0.91525424 0.98687664 0.90806223 0.8203125\n",
      " 1.         0.92307692 1.         0.91869919 0.5        1.\n",
      " 0.69230769 1.         0.94226941 0.91762768 0.90772128 0.96631579]\n",
      "Best epoch: 13 | Best acc: 0.944087\n",
      "Train: epoch: 14 loss: 71.776458 | Acc: 0.923452 | mAP: 0.000000\n",
      "Test: epoch: 14 loss: 54.079351 | Acc: 0.947304 | mAP: 0.000000\n",
      "[1.         0.91712371 0.93220339 0.98687664 0.89108911 0.890625\n",
      " 1.         0.92307692 1.         0.99186992 1.         1.\n",
      " 1.         1.         0.93497014 0.92504119 0.93220339 0.97473684]\n",
      "Best epoch: 14 | Best acc: 0.947304\n",
      "Train: epoch: 15 loss: 69.561110 | Acc: 0.923674 | mAP: 0.000000\n",
      "Test: epoch: 15 loss: 53.891243 | Acc: 0.943089 | mAP: 0.000000\n",
      "[1.         0.92017063 0.91525424 0.98687664 0.91371994 0.390625\n",
      " 1.         0.92307692 1.         0.97560976 1.         1.\n",
      " 1.         1.         0.93828799 0.92174629 0.95291902 0.96631579]\n",
      "Best epoch: 14 | Best acc: 0.947304\n",
      "Train: epoch: 16 loss: 67.129526 | Acc: 0.925893 | mAP: 0.000000\n",
      "Test: epoch: 16 loss: 52.565575 | Acc: 0.944974 | mAP: 0.000000\n",
      "[1.         0.92626447 0.93220339 0.98687664 0.88826025 0.75\n",
      " 1.         0.92307692 1.         0.98373984 1.         1.\n",
      " 1.         1.         0.93430657 0.90856672 0.95480226 0.96210526]\n",
      "Best epoch: 14 | Best acc: 0.947304\n",
      "Train: epoch: 17 loss: 66.093627 | Acc: 0.929332 | mAP: 0.000000\n",
      "Test: epoch: 17 loss: 50.493668 | Acc: 0.945307 | mAP: 0.000000\n",
      "[1.         0.93479586 0.94915254 0.98687664 0.87694484 0.6328125\n",
      " 1.         0.92307692 1.         0.96747967 1.         1.\n",
      " 1.         1.         0.92966158 0.92504119 0.95103578 0.96631579]\n",
      "Best epoch: 14 | Best acc: 0.947304\n",
      "Train: epoch: 18 loss: 63.646330 | Acc: 0.930331 | mAP: 0.000000\n",
      "Test: epoch: 18 loss: 50.498459 | Acc: 0.945640 | mAP: 0.000000\n",
      "[1.         0.93967093 0.94915254 0.98687664 0.84865629 0.7109375\n",
      " 1.         0.92307692 1.         0.95934959 1.         1.\n",
      " 1.         1.         0.94094227 0.92174629 0.93973635 0.96421053]\n",
      "Best epoch: 14 | Best acc: 0.947304\n",
      "Train: epoch: 19 loss: 63.157963 | Acc: 0.929998 | mAP: 0.000000\n",
      "Test: epoch: 19 loss: 50.855939 | Acc: 0.943865 | mAP: 0.000000\n",
      "[1.         0.92078001 0.94915254 0.98687664 0.89108911 0.9296875\n",
      " 1.         0.92307692 1.         0.94308943 1.         1.\n",
      " 1.         1.         0.92236231 0.90444811 0.95103578 0.96842105]\n",
      "Best epoch: 14 | Best acc: 0.947304\n",
      "Train: epoch: 20 loss: 62.294185 | Acc: 0.931107 | mAP: 0.000000\n",
      "Test: epoch: 20 loss: 49.907095 | Acc: 0.942534 | mAP: 0.000000\n",
      "[1.         0.88848263 0.93220339 0.98687664 0.91513437 0.8515625\n",
      " 1.         0.92307692 1.         1.         1.         1.\n",
      " 1.         1.         0.94094227 0.91598023 0.92090395 0.97263158]\n",
      "Best epoch: 14 | Best acc: 0.947304\n",
      "Train: epoch: 21 loss: 60.402069 | Acc: 0.931440 | mAP: 0.000000\n",
      "Test: epoch: 21 loss: 48.604899 | Acc: 0.944531 | mAP: 0.000000\n",
      "[1.         0.95246801 0.96610169 0.98425197 0.84441301 0.515625\n",
      " 1.         0.92307692 1.         0.95121951 1.         1.\n",
      " 1.         1.         0.93165229 0.9324547  0.93785311 0.96421053]\n",
      "Best epoch: 14 | Best acc: 0.947304\n",
      "Train: epoch: 22 loss: 59.936829 | Acc: 0.933659 | mAP: 0.000000\n",
      "Test: epoch: 22 loss: 47.557850 | Acc: 0.945529 | mAP: 0.000000\n",
      "[1.         0.94271785 0.93220339 0.98687664 0.85148515 0.671875\n",
      " 1.         0.92307692 1.         0.95121951 1.         1.\n",
      " 1.         1.         0.93297943 0.9291598  0.94161959 0.96631579]\n",
      "Best epoch: 14 | Best acc: 0.947304\n",
      "Train: epoch: 23 loss: 59.388831 | Acc: 0.934546 | mAP: 0.000000\n",
      "Test: epoch: 23 loss: 47.818131 | Acc: 0.944087 | mAP: 0.000000\n",
      "[1.         0.9213894  0.94915254 0.98687664 0.90664781 0.6796875\n",
      " 1.         0.92307692 1.         0.92682927 1.         1.\n",
      " 1.         1.         0.93629728 0.91186161 0.94161959 0.96631579]\n",
      "Best epoch: 14 | Best acc: 0.947304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: epoch: 24 loss: 58.316690 | Acc: 0.932438 | mAP: 0.000000\n",
      "Test: epoch: 24 loss: 47.112253 | Acc: 0.949634 | mAP: 0.000000\n",
      "[1.         0.92809263 0.94915254 0.98687664 0.89816124 0.7890625\n",
      " 1.         0.92307692 1.         0.92682927 1.         1.\n",
      " 1.         1.         0.93563371 0.93327842 0.95291902 0.96631579]\n",
      "Best epoch: 24 | Best acc: 0.949634\n",
      "Train: epoch: 25 loss: 57.603463 | Acc: 0.936210 | mAP: 0.000000\n",
      "Test: epoch: 25 loss: 46.880654 | Acc: 0.944974 | mAP: 0.000000\n",
      "[1.         0.93540524 0.96610169 0.98687664 0.87553041 0.7421875\n",
      " 1.         0.92307692 1.         0.91869919 1.         1.\n",
      " 1.         1.         0.93629728 0.90939044 0.94161959 0.97052632]\n",
      "Best epoch: 24 | Best acc: 0.949634\n",
      "Train: epoch: 26 loss: 57.521896 | Acc: 0.936210 | mAP: 0.000000\n",
      "Test: epoch: 26 loss: 46.532212 | Acc: 0.944198 | mAP: 0.000000\n",
      "[1.         0.92687386 0.96610169 0.98687664 0.88967468 0.5859375\n",
      " 1.         0.92307692 1.         0.95934959 1.         1.\n",
      " 1.         1.         0.93497014 0.92421746 0.93220339 0.97263158]\n",
      "Best epoch: 24 | Best acc: 0.949634\n",
      "Train: epoch: 27 loss: 56.793923 | Acc: 0.934103 | mAP: 0.000000\n",
      "Test: epoch: 27 loss: 46.830393 | Acc: 0.950189 | mAP: 0.000000\n",
      "[1.         0.92565509 0.94915254 0.98687664 0.90664781 0.78125\n",
      " 1.         0.92307692 1.         0.95934959 1.         1.\n",
      " 1.         1.         0.9270073  0.93163097 0.97928437 0.96842105]\n",
      "Best epoch: 27 | Best acc: 0.950189\n",
      "Train: epoch: 28 loss: 56.047430 | Acc: 0.936099 | mAP: 0.000000\n",
      "Test: epoch: 28 loss: 45.833687 | Acc: 0.949301 | mAP: 0.000000\n",
      "[1.         0.92748324 0.96610169 0.98687664 0.90523338 0.765625\n",
      " 1.         0.92307692 1.         0.94308943 1.         1.\n",
      " 1.         1.         0.93629728 0.9291598  0.94350282 0.97052632]\n",
      "Best epoch: 27 | Best acc: 0.950189\n",
      "Train: epoch: 29 loss: 55.443030 | Acc: 0.937874 | mAP: 0.000000\n",
      "Test: epoch: 29 loss: 46.016151 | Acc: 0.946750 | mAP: 0.000000\n",
      "[1.         0.94698355 0.96610169 0.98425197 0.83734088 0.75\n",
      " 1.         0.92307692 1.         0.95934959 1.         1.\n",
      " 1.         1.         0.93563371 0.93163097 0.93785311 0.96      ]\n",
      "Best epoch: 27 | Best acc: 0.950189\n",
      "Train: epoch: 30 loss: 54.877303 | Acc: 0.939428 | mAP: 0.000000\n",
      "Test: epoch: 30 loss: 45.500196 | Acc: 0.949745 | mAP: 0.000000\n",
      "[1.         0.92626447 0.96610169 0.98687664 0.91371994 0.7578125\n",
      " 1.         0.92307692 1.         0.95934959 1.         1.\n",
      " 1.         1.         0.93497014 0.92998353 0.94350282 0.97052632]\n",
      "Best epoch: 27 | Best acc: 0.950189\n",
      "Train: epoch: 31 loss: 55.109055 | Acc: 0.937653 | mAP: 0.000000\n",
      "Test: epoch: 31 loss: 45.909768 | Acc: 0.942312 | mAP: 0.000000\n",
      "[1.         0.95429616 0.96610169 0.98425197 0.85148515 0.3515625\n",
      " 1.         0.92307692 1.         0.90243902 1.         1.\n",
      " 1.         1.         0.9203716  0.94151565 0.94161959 0.97052632]\n",
      "Best epoch: 27 | Best acc: 0.950189\n",
      "Train: epoch: 32 loss: 54.434813 | Acc: 0.937320 | mAP: 0.000000\n",
      "Test: epoch: 32 loss: 45.412875 | Acc: 0.946750 | mAP: 0.000000\n",
      "[1.         0.92321755 0.96610169 0.98687664 0.91796322 0.8046875\n",
      " 1.         0.92307692 1.         0.8699187  1.         1.\n",
      " 1.         1.         0.94160584 0.90444811 0.94161959 0.97473684]\n",
      "Best epoch: 27 | Best acc: 0.950189\n",
      "Train: epoch: 33 loss: 54.280506 | Acc: 0.936876 | mAP: 0.000000\n",
      "Test: epoch: 33 loss: 45.919995 | Acc: 0.943976 | mAP: 0.000000\n",
      "[1.         0.88299817 0.94915254 0.98687664 0.90806223 0.9921875\n",
      " 1.         0.92307692 1.         0.98373984 1.         1.\n",
      " 1.         1.         0.93961513 0.91680395 0.93973635 0.97473684]\n",
      "Best epoch: 27 | Best acc: 0.950189\n",
      "Train: epoch: 34 loss: 53.421992 | Acc: 0.938651 | mAP: 0.000000\n",
      "Test: epoch: 34 loss: 45.943870 | Acc: 0.942201 | mAP: 0.000000\n",
      "[1.         0.90737355 0.94915254 0.98687664 0.87977369 0.9140625\n",
      " 1.         0.92307692 1.         0.91869919 1.         1.\n",
      " 1.         1.         0.93629728 0.90856672 0.94161959 0.96631579]\n",
      "Best epoch: 27 | Best acc: 0.950189\n",
      "Train: epoch: 35 loss: 53.387731 | Acc: 0.938873 | mAP: 0.000000\n",
      "Test: epoch: 35 loss: 45.169155 | Acc: 0.948857 | mAP: 0.000000\n",
      "[1.         0.91834247 0.94915254 0.98687664 0.92786421 0.796875\n",
      " 1.         0.92307692 1.         0.91056911 1.         1.\n",
      " 1.         1.         0.93762442 0.92586491 0.93973635 0.97052632]\n",
      "Best epoch: 27 | Best acc: 0.950189\n",
      "Train: epoch: 36 loss: 53.064776 | Acc: 0.938540 | mAP: 0.000000\n",
      "Test: epoch: 36 loss: 45.429980 | Acc: 0.944309 | mAP: 0.000000\n",
      "[1.         0.94637416 0.94915254 0.98687664 0.8387553  0.6015625\n",
      " 1.         0.92307692 1.         0.95934959 1.         1.\n",
      " 1.         1.         0.9270073  0.9398682  0.93220339 0.96631579]\n",
      "Best epoch: 27 | Best acc: 0.950189\n",
      "Train: epoch: 37 loss: 52.487306 | Acc: 0.940093 | mAP: 0.000000\n",
      "Test: epoch: 37 loss: 44.913607 | Acc: 0.945196 | mAP: 0.000000\n",
      "[1.         0.93601463 0.96610169 0.98687664 0.86704385 0.75\n",
      " 1.         0.92307692 1.         0.90243902 1.         1.\n",
      " 1.         1.         0.94625083 0.90280066 0.94161959 0.97263158]\n",
      "Best epoch: 27 | Best acc: 0.950189\n",
      "Train: epoch: 38 loss: 52.122127 | Acc: 0.939095 | mAP: 0.000000\n",
      "Test: epoch: 38 loss: 44.409789 | Acc: 0.949412 | mAP: 0.000000\n",
      "[1.         0.92687386 0.96610169 0.99212598 0.90523338 0.7734375\n",
      " 1.         0.92307692 1.         0.95934959 1.         1.\n",
      " 1.         1.         0.93828799 0.92586491 0.94161959 0.96842105]\n",
      "Best epoch: 27 | Best acc: 0.950189\n",
      "Train: epoch: 39 loss: 52.353166 | Acc: 0.942867 | mAP: 0.000000\n",
      "Test: epoch: 39 loss: 44.783223 | Acc: 0.947526 | mAP: 0.000000\n",
      "[1.         0.92443632 0.96610169 0.98687664 0.92220651 0.7578125\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.95023225 0.90691928 0.92278719 0.96631579]\n",
      "Best epoch: 27 | Best acc: 0.950189\n",
      "Train: epoch: 40 loss: 51.912049 | Acc: 0.938651 | mAP: 0.000000\n",
      "Test: epoch: 40 loss: 44.268442 | Acc: 0.949745 | mAP: 0.000000\n",
      "[1.         0.92748324 0.94915254 0.98687664 0.92786421 0.765625\n",
      " 1.         1.         1.         0.88617886 1.         1.\n",
      " 1.         1.         0.92966158 0.93327842 0.94161959 0.97263158]\n",
      "Best epoch: 27 | Best acc: 0.950189\n",
      "Train: epoch: 41 loss: 51.691985 | Acc: 0.939317 | mAP: 0.000000\n",
      "Test: epoch: 41 loss: 44.487840 | Acc: 0.948746 | mAP: 0.000000\n",
      "[1.         0.92382693 0.94915254 0.98687664 0.91796322 0.78125\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.93297943 0.92257002 0.95291902 0.97473684]\n",
      "Best epoch: 27 | Best acc: 0.950189\n",
      "Train: epoch: 42 loss: 51.544878 | Acc: 0.939428 | mAP: 0.000000\n",
      "Test: epoch: 42 loss: 43.884440 | Acc: 0.948414 | mAP: 0.000000\n",
      "[1.         0.91895186 1.         0.98950131 0.93635078 0.765625\n",
      " 1.         1.         1.         0.84552846 1.         1.\n",
      " 1.         1.         0.93961513 0.92009885 0.94161959 0.96842105]\n",
      "Best epoch: 27 | Best acc: 0.950189\n",
      "Train: epoch: 43 loss: 51.355479 | Acc: 0.940093 | mAP: 0.000000\n",
      "Test: epoch: 43 loss: 44.364099 | Acc: 0.948857 | mAP: 0.000000\n",
      "[1.         0.91651432 0.96610169 0.98687664 0.94483734 0.7421875\n",
      " 1.         1.         1.         0.82113821 1.         1.\n",
      " 1.         1.         0.94824154 0.91598023 0.94161959 0.97473684]\n",
      "Best epoch: 27 | Best acc: 0.950189\n",
      "Train: epoch: 44 loss: 50.920226 | Acc: 0.939649 | mAP: 0.000000\n",
      "Test: epoch: 44 loss: 43.749882 | Acc: 0.944531 | mAP: 0.000000\n",
      "[1.         0.9213894  0.94915254 0.98687664 0.87411598 0.7890625\n",
      " 1.         1.         1.         0.8699187  1.         1.\n",
      " 1.         1.         0.93497014 0.92668863 0.94161959 0.97263158]\n",
      "Best epoch: 27 | Best acc: 0.950189\n",
      "Train: epoch: 45 loss: 50.072080 | Acc: 0.943199 | mAP: 0.000000\n",
      "Test: epoch: 45 loss: 44.567182 | Acc: 0.946750 | mAP: 0.000000\n",
      "[1.         0.92992078 0.96610169 0.98687664 0.89816124 0.75\n",
      " 1.         1.         1.         0.91869919 1.         1.\n",
      " 1.         1.         0.9469144  0.90115321 0.94161959 0.97263158]\n",
      "Best epoch: 27 | Best acc: 0.950189\n",
      "Train: epoch: 46 loss: 50.565290 | Acc: 0.940315 | mAP: 0.000000\n",
      "Test: epoch: 46 loss: 43.461397 | Acc: 0.947526 | mAP: 0.000000\n",
      "[1.         0.9250457  0.96610169 0.98687664 0.9165488  0.7578125\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.93762442 0.91433278 0.94161959 0.97263158]\n",
      "Best epoch: 27 | Best acc: 0.950189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: epoch: 47 loss: 50.481581 | Acc: 0.941314 | mAP: 0.000000\n",
      "Test: epoch: 47 loss: 45.018283 | Acc: 0.948303 | mAP: 0.000000\n",
      "[1.         0.92687386 0.96610169 0.98687664 0.89533239 0.75\n",
      " 1.         1.         1.         0.95934959 1.         1.\n",
      " 1.         1.         0.94890511 0.90856672 0.95480226 0.96631579]\n",
      "Best epoch: 27 | Best acc: 0.950189\n",
      "Train: epoch: 48 loss: 50.775249 | Acc: 0.940648 | mAP: 0.000000\n",
      "Test: epoch: 48 loss: 43.416329 | Acc: 0.949190 | mAP: 0.000000\n",
      "[1.         0.92870201 0.94915254 0.98687664 0.92362093 0.640625\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.93231586 0.93657331 0.94161959 0.97473684]\n",
      "Best epoch: 27 | Best acc: 0.950189\n",
      "Train: epoch: 49 loss: 49.980672 | Acc: 0.942756 | mAP: 0.000000\n",
      "Test: epoch: 49 loss: 44.152036 | Acc: 0.947304 | mAP: 0.000000\n",
      "[1.         0.92809263 0.96610169 0.98687664 0.90947666 0.7421875\n",
      " 1.         1.         1.         0.96747967 1.         1.\n",
      " 1.         1.         0.94359655 0.90032949 0.94161959 0.97473684]\n",
      "Best epoch: 27 | Best acc: 0.950189\n",
      "Train: epoch: 50 loss: 49.163778 | Acc: 0.942201 | mAP: 0.000000\n",
      "Test: epoch: 50 loss: 44.035801 | Acc: 0.947082 | mAP: 0.000000\n",
      "[1.         0.92443632 0.94915254 0.98687664 0.9165488  0.8046875\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.93961513 0.90939044 0.93973635 0.96421053]\n",
      "Best epoch: 27 | Best acc: 0.950189\n",
      "Train: epoch: 51 loss: 49.976955 | Acc: 0.942090 | mAP: 0.000000\n",
      "Test: epoch: 51 loss: 43.718495 | Acc: 0.947748 | mAP: 0.000000\n",
      "[1.         0.93418647 0.96610169 0.98425197 0.85997171 0.7578125\n",
      " 1.         1.         1.         0.95934959 1.         1.\n",
      " 1.         1.         0.92833444 0.94563427 0.94161959 0.96842105]\n",
      "Best epoch: 27 | Best acc: 0.950189\n",
      "Train: epoch: 52 loss: 49.475433 | Acc: 0.941314 | mAP: 0.000000\n",
      "Test: epoch: 52 loss: 43.893427 | Acc: 0.947304 | mAP: 0.000000\n",
      "[1.         0.92748324 1.         0.98950131 0.87270156 0.7578125\n",
      " 1.         1.         1.         0.96747967 1.         1.\n",
      " 1.         1.         0.9402787  0.92339374 0.94161959 0.97263158]\n",
      "Best epoch: 27 | Best acc: 0.950189\n",
      "Train: epoch: 53 loss: 49.184466 | Acc: 0.940870 | mAP: 0.000000\n",
      "Test: epoch: 53 loss: 43.631108 | Acc: 0.947970 | mAP: 0.000000\n",
      "[1.         0.93479586 0.98305085 0.98687664 0.86562942 0.765625\n",
      " 1.         1.         1.         0.95934959 1.         1.\n",
      " 1.         1.         0.93895156 0.9291598  0.94161959 0.96421053]\n",
      "Best epoch: 27 | Best acc: 0.950189\n",
      "Train: epoch: 54 loss: 49.110875 | Acc: 0.942534 | mAP: 0.000000\n",
      "Test: epoch: 54 loss: 43.163414 | Acc: 0.949967 | mAP: 0.000000\n",
      "[1.         0.92565509 0.94915254 0.98687664 0.92362093 0.75\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.94293298 0.92257002 0.94161959 0.97263158]\n",
      "Best epoch: 27 | Best acc: 0.950189\n",
      "Train: epoch: 55 loss: 49.497046 | Acc: 0.940204 | mAP: 0.000000\n",
      "Test: epoch: 55 loss: 43.206378 | Acc: 0.946306 | mAP: 0.000000\n",
      "[1.         0.93601463 0.94915254 0.97900262 0.87835926 0.7265625\n",
      " 1.         1.         1.         0.92682927 1.         1.\n",
      " 1.         1.         0.93762442 0.91762768 0.94161959 0.97263158]\n",
      "Best epoch: 27 | Best acc: 0.950189\n",
      "Train: epoch: 56 loss: 48.591931 | Acc: 0.940093 | mAP: 0.000000\n",
      "Test: epoch: 56 loss: 43.429854 | Acc: 0.950854 | mAP: 0.000000\n",
      "[1.         0.92809263 0.94915254 0.98950131 0.90947666 0.828125\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.92899801 0.94233937 0.94161959 0.97263158]\n",
      "Best epoch: 56 | Best acc: 0.950854\n",
      "Train: epoch: 57 loss: 48.674250 | Acc: 0.942201 | mAP: 0.000000\n",
      "Test: epoch: 57 loss: 43.397273 | Acc: 0.946306 | mAP: 0.000000\n",
      "[1.         0.93723339 0.96610169 0.98687664 0.87835926 0.75\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.93629728 0.91268534 0.94161959 0.97473684]\n",
      "Best epoch: 56 | Best acc: 0.950854\n",
      "Train: epoch: 58 loss: 48.611294 | Acc: 0.942645 | mAP: 0.000000\n",
      "Test: epoch: 58 loss: 43.504428 | Acc: 0.943976 | mAP: 0.000000\n",
      "[1.         0.93540524 1.         0.98425197 0.85007072 0.7578125\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.9402787  0.91021417 0.94161959 0.96842105]\n",
      "Best epoch: 56 | Best acc: 0.950854\n",
      "Train: epoch: 59 loss: 48.792309 | Acc: 0.944420 | mAP: 0.000000\n",
      "Test: epoch: 59 loss: 43.130145 | Acc: 0.946417 | mAP: 0.000000\n",
      "[1.         0.93784278 1.         0.98687664 0.854314   0.75\n",
      " 1.         1.         1.         0.89430894 1.         1.\n",
      " 1.         1.         0.94492369 0.91680395 0.94161959 0.97263158]\n",
      "Best epoch: 56 | Best acc: 0.950854\n",
      "Train: epoch: 60 loss: 48.474362 | Acc: 0.942867 | mAP: 0.000000\n",
      "Test: epoch: 60 loss: 44.444120 | Acc: 0.945307 | mAP: 0.000000\n",
      "[1.         0.95246801 0.94915254 0.98425197 0.8387553  0.734375\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.9469144  0.89868204 0.94161959 0.97263158]\n",
      "Best epoch: 56 | Best acc: 0.950854\n",
      "Train: epoch: 61 loss: 48.276135 | Acc: 0.944420 | mAP: 0.000000\n",
      "Test: epoch: 61 loss: 43.238212 | Acc: 0.948192 | mAP: 0.000000\n",
      "[1.         0.9329677  0.98305085 0.98687664 0.90806223 0.75\n",
      " 1.         1.         1.         0.82113821 1.         1.\n",
      " 1.         1.         0.92501659 0.93904448 0.93973635 0.97263158]\n",
      "Best epoch: 56 | Best acc: 0.950854\n",
      "Train: epoch: 62 loss: 48.501822 | Acc: 0.943865 | mAP: 0.000000\n",
      "Test: epoch: 62 loss: 43.265342 | Acc: 0.949523 | mAP: 0.000000\n",
      "[1.         0.92382693 0.94915254 0.98687664 0.93069307 0.7421875\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.93828799 0.92586491 0.94161959 0.96842105]\n",
      "Best epoch: 56 | Best acc: 0.950854\n",
      "Train: epoch: 63 loss: 48.250821 | Acc: 0.941646 | mAP: 0.000000\n",
      "Test: epoch: 63 loss: 43.715238 | Acc: 0.945418 | mAP: 0.000000\n",
      "[1.         0.88787325 0.94915254 0.98950131 0.93352192 0.9921875\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.94426012 0.90609555 0.94161959 0.97263158]\n",
      "Best epoch: 56 | Best acc: 0.950854\n",
      "Train: epoch: 64 loss: 48.161357 | Acc: 0.942645 | mAP: 0.000000\n",
      "Test: epoch: 64 loss: 43.226977 | Acc: 0.945973 | mAP: 0.000000\n",
      "[1.         0.93113955 0.96610169 0.98687664 0.86845827 0.75\n",
      " 1.         1.         1.         0.95121951 1.         1.\n",
      " 1.         1.         0.94824154 0.90609555 0.94161959 0.97263158]\n",
      "Best epoch: 56 | Best acc: 0.950854\n",
      "Train: epoch: 65 loss: 48.578614 | Acc: 0.941203 | mAP: 0.000000\n",
      "Test: epoch: 65 loss: 42.861909 | Acc: 0.949079 | mAP: 0.000000\n",
      "[1.         0.9488117  0.96610169 0.98687664 0.85997171 0.75\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.93563371 0.9291598  0.94161959 0.97473684]\n",
      "Best epoch: 56 | Best acc: 0.950854\n",
      "Train: epoch: 66 loss: 47.742071 | Acc: 0.943310 | mAP: 0.000000\n",
      "Test: epoch: 66 loss: 43.965140 | Acc: 0.942978 | mAP: 0.000000\n",
      "[1.         0.95429616 0.96610169 0.98425197 0.86704385 0.2890625\n",
      " 1.         1.         1.         0.90243902 1.         1.\n",
      " 1.         1.         0.92568016 0.94481054 0.92467043 0.96842105]\n",
      "Best epoch: 56 | Best acc: 0.950854\n",
      "Train: epoch: 67 loss: 47.924469 | Acc: 0.943865 | mAP: 0.000000\n",
      "Test: epoch: 67 loss: 43.055067 | Acc: 0.947082 | mAP: 0.000000\n",
      "[1.         0.93540524 0.94915254 0.97900262 0.87553041 0.75\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.93762442 0.92421746 0.94161959 0.97473684]\n",
      "Best epoch: 56 | Best acc: 0.950854\n",
      "Train: epoch: 68 loss: 47.927311 | Acc: 0.943089 | mAP: 0.000000\n",
      "Test: epoch: 68 loss: 43.273822 | Acc: 0.947193 | mAP: 0.000000\n",
      "[1.         0.92687386 1.         0.98687664 0.90240453 0.75\n",
      " 1.         1.         1.         0.95934959 1.         1.\n",
      " 1.         1.         0.93563371 0.91350906 0.94161959 0.97473684]\n",
      "Best epoch: 56 | Best acc: 0.950854\n",
      "Train: epoch: 69 loss: 47.673234 | Acc: 0.942645 | mAP: 0.000000\n",
      "Test: epoch: 69 loss: 42.805733 | Acc: 0.948192 | mAP: 0.000000\n",
      "[1.         0.94820232 0.96610169 0.98687664 0.84441301 0.734375\n",
      " 1.         1.         1.         0.93495935 1.         1.\n",
      " 1.         1.         0.93563371 0.93163097 0.94161959 0.97473684]\n",
      "Best epoch: 56 | Best acc: 0.950854\n",
      "Train: epoch: 70 loss: 47.289810 | Acc: 0.940648 | mAP: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: epoch: 70 loss: 42.907676 | Acc: 0.948968 | mAP: 0.000000\n",
      "[1.         0.93723339 1.         0.98687664 0.87411598 0.7578125\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.94226941 0.9291598  0.93408663 0.97263158]\n",
      "Best epoch: 56 | Best acc: 0.950854\n",
      "Train: epoch: 71 loss: 47.567824 | Acc: 0.943310 | mAP: 0.000000\n",
      "Test: epoch: 71 loss: 42.913863 | Acc: 0.946971 | mAP: 0.000000\n",
      "[1.         0.9329677  0.96610169 0.98687664 0.8854314  0.75\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.93497014 0.92257002 0.94161959 0.97052632]\n",
      "Best epoch: 56 | Best acc: 0.950854\n",
      "Train: epoch: 72 loss: 47.590756 | Acc: 0.944531 | mAP: 0.000000\n",
      "Test: epoch: 72 loss: 42.723470 | Acc: 0.948857 | mAP: 0.000000\n",
      "[1.         0.94759293 0.94915254 0.98687664 0.85289958 0.75\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.93231586 0.93904448 0.94161959 0.97263158]\n",
      "Best epoch: 56 | Best acc: 0.950854\n",
      "Train: epoch: 73 loss: 47.115714 | Acc: 0.943532 | mAP: 0.000000\n",
      "Test: epoch: 73 loss: 42.616727 | Acc: 0.949967 | mAP: 0.000000\n",
      "[1.         0.93113955 0.96610169 0.98687664 0.90806223 0.75\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.93961513 0.92751236 0.94161959 0.97263158]\n",
      "Best epoch: 56 | Best acc: 0.950854\n",
      "Train: epoch: 74 loss: 47.297236 | Acc: 0.944531 | mAP: 0.000000\n",
      "Test: epoch: 74 loss: 42.820697 | Acc: 0.946971 | mAP: 0.000000\n",
      "[1.         0.94637416 0.98305085 0.98687664 0.84724187 0.7578125\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.93762442 0.92092257 0.94161959 0.97263158]\n",
      "Best epoch: 56 | Best acc: 0.950854\n",
      "Train: epoch: 75 loss: 47.028608 | Acc: 0.942423 | mAP: 0.000000\n",
      "Test: epoch: 75 loss: 43.284960 | Acc: 0.947193 | mAP: 0.000000\n",
      "[1.         0.92992078 0.96610169 0.98687664 0.9165488  0.6015625\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.92568016 0.93739703 0.93973635 0.97263158]\n",
      "Best epoch: 56 | Best acc: 0.950854\n",
      "Train: epoch: 76 loss: 47.018431 | Acc: 0.942978 | mAP: 0.000000\n",
      "Test: epoch: 76 loss: 43.041441 | Acc: 0.949412 | mAP: 0.000000\n",
      "[1.         0.92199878 0.96610169 0.98687664 0.92644979 0.75\n",
      " 1.         1.         1.         0.91869919 1.         1.\n",
      " 1.         1.         0.92302588 0.94645799 0.94161959 0.96842105]\n",
      "Best epoch: 56 | Best acc: 0.950854\n",
      "Train: epoch: 77 loss: 47.093366 | Acc: 0.944753 | mAP: 0.000000\n",
      "Test: epoch: 77 loss: 42.666992 | Acc: 0.948746 | mAP: 0.000000\n",
      "[1.         0.93053016 0.94915254 0.98687664 0.89674682 0.75\n",
      " 1.         1.         1.         0.92682927 1.         1.\n",
      " 1.         1.         0.93629728 0.92833608 0.94161959 0.97473684]\n",
      "Best epoch: 56 | Best acc: 0.950854\n",
      "Train: epoch: 78 loss: 47.235426 | Acc: 0.944531 | mAP: 0.000000\n",
      "Test: epoch: 78 loss: 42.662710 | Acc: 0.946971 | mAP: 0.000000\n",
      "[1.         0.92078001 0.94915254 0.98687664 0.94200849 0.75\n",
      " 1.         1.         1.         0.80487805 1.         1.\n",
      " 1.         1.         0.94094227 0.90856672 0.94161959 0.97473684]\n",
      "Best epoch: 56 | Best acc: 0.950854\n",
      "Train: epoch: 79 loss: 47.193024 | Acc: 0.942756 | mAP: 0.000000\n",
      "Test: epoch: 79 loss: 42.583502 | Acc: 0.948303 | mAP: 0.000000\n",
      "[1.         0.93479586 0.94915254 0.98687664 0.8854314  0.7265625\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.93762442 0.92833608 0.94161959 0.97473684]\n",
      "Best epoch: 56 | Best acc: 0.950854\n",
      "Train: epoch: 80 loss: 47.206005 | Acc: 0.942978 | mAP: 0.000000\n",
      "Test: epoch: 80 loss: 42.688877 | Acc: 0.950189 | mAP: 0.000000\n",
      "[1.         0.92260817 0.98305085 0.98687664 0.93493635 0.75\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.92302588 0.94481054 0.94161959 0.97263158]\n",
      "Best epoch: 56 | Best acc: 0.950854\n",
      "Train: epoch: 81 loss: 46.881842 | Acc: 0.942978 | mAP: 0.000000\n",
      "Test: epoch: 81 loss: 42.635995 | Acc: 0.948746 | mAP: 0.000000\n",
      "[1.         0.92748324 0.94915254 0.98687664 0.92644979 0.75\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.93762442 0.91515651 0.94161959 0.97473684]\n",
      "Best epoch: 56 | Best acc: 0.950854\n",
      "Train: epoch: 82 loss: 46.941574 | Acc: 0.942423 | mAP: 0.000000\n",
      "Test: epoch: 82 loss: 42.614182 | Acc: 0.950410 | mAP: 0.000000\n",
      "[1.         0.93113955 0.94915254 0.98687664 0.91937765 0.75\n",
      " 1.         1.         1.         0.90243902 1.         1.\n",
      " 1.         1.         0.94757797 0.9184514  0.93973635 0.96842105]\n",
      "Best epoch: 56 | Best acc: 0.950854\n",
      "Train: epoch: 83 loss: 46.622265 | Acc: 0.943976 | mAP: 0.000000\n",
      "Test: epoch: 83 loss: 43.006605 | Acc: 0.949745 | mAP: 0.000000\n",
      "[1.         0.91773309 0.94915254 0.98425197 0.91796322 0.875\n",
      " 1.         1.         1.         0.91869919 1.         1.\n",
      " 1.         1.         0.93098872 0.93574959 0.94350282 0.97263158]\n",
      "Best epoch: 56 | Best acc: 0.950854\n",
      "Train: epoch: 84 loss: 46.684984 | Acc: 0.944198 | mAP: 0.000000\n",
      "Test: epoch: 84 loss: 43.176801 | Acc: 0.947970 | mAP: 0.000000\n",
      "[1.         0.9488117  0.94915254 0.98425197 0.84441301 0.765625\n",
      " 1.         1.         1.         0.89430894 1.         1.\n",
      " 1.         1.         0.94226941 0.92504119 0.94161959 0.97052632]\n",
      "Best epoch: 56 | Best acc: 0.950854\n",
      "Train: epoch: 85 loss: 46.306206 | Acc: 0.944198 | mAP: 0.000000\n",
      "Test: epoch: 85 loss: 43.094225 | Acc: 0.948303 | mAP: 0.000000\n",
      "[1.         0.93418647 0.96610169 0.98687664 0.9165488  0.75\n",
      " 1.         1.         1.         0.82113821 1.         1.\n",
      " 1.         1.         0.93961513 0.92174629 0.92467043 0.97473684]\n",
      "Best epoch: 56 | Best acc: 0.950854\n",
      "Train: epoch: 86 loss: 46.711657 | Acc: 0.943421 | mAP: 0.000000\n",
      "Test: epoch: 86 loss: 42.549386 | Acc: 0.949412 | mAP: 0.000000\n",
      "[1.         0.91407678 0.96610169 0.98687664 0.93352192 0.828125\n",
      " 0.99585921 1.         1.         0.87804878 1.         1.\n",
      " 1.         1.         0.933643   0.93574959 0.94161959 0.97263158]\n",
      "Best epoch: 56 | Best acc: 0.950854\n",
      "Train: epoch: 87 loss: 46.610971 | Acc: 0.944198 | mAP: 0.000000\n",
      "Test: epoch: 87 loss: 42.849853 | Acc: 0.949745 | mAP: 0.000000\n",
      "[1.         0.9293114  0.98305085 0.98687664 0.91089109 0.75\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.92169874 0.94810544 0.94161959 0.97263158]\n",
      "Best epoch: 56 | Best acc: 0.950854\n",
      "Train: epoch: 88 loss: 46.780907 | Acc: 0.943532 | mAP: 0.000000\n",
      "Test: epoch: 88 loss: 42.287494 | Acc: 0.947859 | mAP: 0.000000\n",
      "[1.         0.93113955 0.96610169 0.98687664 0.90240453 0.75\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.93828799 0.91598023 0.94161959 0.97473684]\n",
      "Best epoch: 56 | Best acc: 0.950854\n",
      "Train: epoch: 89 loss: 46.655648 | Acc: 0.944420 | mAP: 0.000000\n",
      "Test: epoch: 89 loss: 42.254229 | Acc: 0.948746 | mAP: 0.000000\n",
      "[1.         0.9293114  0.94915254 0.98687664 0.89674682 0.75\n",
      " 1.         1.         1.         0.91869919 1.         1.\n",
      " 1.         1.         0.93098872 0.93822076 0.94161959 0.97263158]\n",
      "Best epoch: 56 | Best acc: 0.950854\n",
      "Train: epoch: 90 loss: 46.849857 | Acc: 0.943310 | mAP: 0.000000\n",
      "Test: epoch: 90 loss: 42.452846 | Acc: 0.947637 | mAP: 0.000000\n",
      "[1.         0.92626447 0.94915254 0.98425197 0.91230552 0.75\n",
      " 1.         1.         1.         0.79674797 1.         1.\n",
      " 1.         1.         0.93961513 0.92751236 0.94161959 0.97263158]\n",
      "Best epoch: 56 | Best acc: 0.950854\n",
      "Train: epoch: 91 loss: 46.443665 | Acc: 0.943421 | mAP: 0.000000\n",
      "Test: epoch: 91 loss: 42.219059 | Acc: 0.949190 | mAP: 0.000000\n",
      "[1.         0.92748324 0.96610169 0.98687664 0.9009901  0.75\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.93430657 0.93657331 0.94161959 0.97473684]\n",
      "Best epoch: 56 | Best acc: 0.950854\n",
      "Train: epoch: 92 loss: 46.386819 | Acc: 0.945418 | mAP: 0.000000\n",
      "Test: epoch: 92 loss: 42.606624 | Acc: 0.949079 | mAP: 0.000000\n",
      "[1.         0.92260817 1.         0.98687664 0.91371994 0.75\n",
      " 1.         1.         1.         0.93495935 1.         1.\n",
      " 1.         1.         0.93430657 0.93080725 0.94161959 0.97473684]\n",
      "Best epoch: 56 | Best acc: 0.950854\n",
      "Train: epoch: 93 loss: 46.611351 | Acc: 0.944198 | mAP: 0.000000\n",
      "Test: epoch: 93 loss: 42.635901 | Acc: 0.947970 | mAP: 0.000000\n",
      "[1.         0.94576478 0.98305085 0.98687664 0.84724187 0.75\n",
      " 1.         1.         1.         0.90243902 1.         1.\n",
      " 1.         1.         0.93629728 0.93163097 0.94161959 0.97473684]\n",
      "Best epoch: 56 | Best acc: 0.950854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: epoch: 94 loss: 46.191159 | Acc: 0.946860 | mAP: 0.000000\n",
      "Test: epoch: 94 loss: 42.776588 | Acc: 0.946084 | mAP: 0.000000\n",
      "[1.         0.93235832 0.96610169 0.98687664 0.88118812 0.75\n",
      " 1.         1.         1.         0.90243902 1.         1.\n",
      " 1.         1.         0.95023225 0.90032949 0.94161959 0.97263158]\n",
      "Best epoch: 56 | Best acc: 0.950854\n",
      "Train: epoch: 95 loss: 46.282883 | Acc: 0.943089 | mAP: 0.000000\n",
      "Test: epoch: 95 loss: 42.693340 | Acc: 0.946750 | mAP: 0.000000\n",
      "[1.         0.93479586 0.94915254 0.98687664 0.87270156 0.75\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.94094227 0.91762768 0.94161959 0.97473684]\n",
      "Best epoch: 56 | Best acc: 0.950854\n",
      "Train: epoch: 96 loss: 46.217405 | Acc: 0.945529 | mAP: 0.000000\n",
      "Test: epoch: 96 loss: 42.541985 | Acc: 0.949412 | mAP: 0.000000\n",
      "[1.         0.92626447 0.94915254 0.98687664 0.92362093 0.75\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.93165229 0.9324547  0.94161959 0.97052632]\n",
      "Best epoch: 56 | Best acc: 0.950854\n",
      "Train: epoch: 97 loss: 46.359191 | Acc: 0.944309 | mAP: 0.000000\n",
      "Test: epoch: 97 loss: 42.218012 | Acc: 0.947415 | mAP: 0.000000\n",
      "[1.         0.93479586 0.94915254 0.98687664 0.88260255 0.6875\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.93563371 0.93080725 0.94161959 0.97263158]\n",
      "Best epoch: 56 | Best acc: 0.950854\n",
      "Train: epoch: 98 loss: 46.152822 | Acc: 0.944642 | mAP: 0.000000\n",
      "Test: epoch: 98 loss: 42.390561 | Acc: 0.945640 | mAP: 0.000000\n",
      "[1.         0.93540524 0.96610169 0.98687664 0.86704385 0.75\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.933643   0.92009885 0.94161959 0.97473684]\n",
      "Best epoch: 56 | Best acc: 0.950854\n",
      "Train: epoch: 99 loss: 45.989344 | Acc: 0.944087 | mAP: 0.000000\n",
      "Test: epoch: 99 loss: 42.409840 | Acc: 0.949523 | mAP: 0.000000\n",
      "[1.         0.9213894  0.98305085 0.98950131 0.92927864 0.75\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.93828799 0.92421746 0.94161959 0.97473684]\n",
      "Best epoch: 56 | Best acc: 0.950854\n",
      "Train: epoch: 100 loss: 45.898347 | Acc: 0.942978 | mAP: 0.000000\n",
      "Test: epoch: 100 loss: 42.385734 | Acc: 0.950410 | mAP: 0.000000\n",
      "[1.         0.92017063 0.96610169 0.98687664 0.93493635 0.75\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.93563371 0.93410214 0.94161959 0.97473684]\n",
      "Best epoch: 56 | Best acc: 0.950854\n",
      "Train: epoch: 101 loss: 46.251651 | Acc: 0.945085 | mAP: 0.000000\n",
      "Test: epoch: 101 loss: 42.323105 | Acc: 0.949523 | mAP: 0.000000\n",
      "[1.         0.92809263 0.96610169 0.98687664 0.90664781 0.75\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.93430657 0.93739703 0.94161959 0.96842105]\n",
      "Best epoch: 56 | Best acc: 0.950854\n",
      "Train: epoch: 102 loss: 46.190057 | Acc: 0.946306 | mAP: 0.000000\n",
      "Test: epoch: 102 loss: 42.364595 | Acc: 0.948192 | mAP: 0.000000\n",
      "[1.         0.93235832 0.94915254 0.98687664 0.88118812 0.75\n",
      " 1.         1.         1.         0.90243902 1.         1.\n",
      " 1.         1.         0.94359655 0.92174629 0.94915254 0.97263158]\n",
      "Best epoch: 56 | Best acc: 0.950854\n",
      "Train: epoch: 103 loss: 45.659552 | Acc: 0.944974 | mAP: 0.000000\n",
      "Test: epoch: 103 loss: 42.100389 | Acc: 0.950854 | mAP: 0.000000\n",
      "[1.         0.92687386 0.96610169 0.98425197 0.92644979 0.75\n",
      " 1.         1.         1.         0.90243902 1.         1.\n",
      " 1.         1.         0.93762442 0.93327842 0.94161959 0.97263158]\n",
      "Best epoch: 103 | Best acc: 0.950854\n",
      "Train: epoch: 104 loss: 45.964667 | Acc: 0.944753 | mAP: 0.000000\n",
      "Test: epoch: 104 loss: 42.142545 | Acc: 0.948746 | mAP: 0.000000\n",
      "[1.         0.93723339 0.94915254 0.98687664 0.88684583 0.75\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.93032515 0.93410214 0.94161959 0.97473684]\n",
      "Best epoch: 103 | Best acc: 0.950854\n",
      "Train: epoch: 105 loss: 45.608114 | Acc: 0.944864 | mAP: 0.000000\n",
      "Test: epoch: 105 loss: 42.736784 | Acc: 0.948635 | mAP: 0.000000\n",
      "[1.         0.92443632 0.94915254 0.98687664 0.94059406 0.75\n",
      " 1.         1.         1.         0.80487805 1.         1.\n",
      " 1.         1.         0.93563371 0.92339374 0.94161959 0.97473684]\n",
      "Best epoch: 103 | Best acc: 0.950854\n",
      "Train: epoch: 106 loss: 45.625146 | Acc: 0.944531 | mAP: 0.000000\n",
      "Test: epoch: 106 loss: 42.519610 | Acc: 0.948081 | mAP: 0.000000\n",
      "[1.         0.92199878 0.96610169 0.98687664 0.93635078 0.75\n",
      " 1.         1.         1.         0.87804878 1.         1.\n",
      " 1.         1.         0.93629728 0.91680395 0.94161959 0.97263158]\n",
      "Best epoch: 103 | Best acc: 0.950854\n",
      "Train: epoch: 107 loss: 45.799191 | Acc: 0.944642 | mAP: 0.000000\n",
      "Test: epoch: 107 loss: 42.259113 | Acc: 0.948414 | mAP: 0.000000\n",
      "[1.         0.93235832 0.94915254 0.98950131 0.87553041 0.75\n",
      " 1.         1.         1.         0.92682927 1.         1.\n",
      " 1.         1.         0.92568016 0.94810544 0.94161959 0.97473684]\n",
      "Best epoch: 103 | Best acc: 0.950854\n",
      "Train: epoch: 108 loss: 45.780660 | Acc: 0.943976 | mAP: 0.000000\n",
      "Test: epoch: 108 loss: 42.452310 | Acc: 0.946528 | mAP: 0.000000\n",
      "[1.         0.93418647 0.94915254 0.98687664 0.87270156 0.75\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.93563371 0.92586491 0.93596987 0.97473684]\n",
      "Best epoch: 103 | Best acc: 0.950854\n",
      "Train: epoch: 109 loss: 45.676621 | Acc: 0.943421 | mAP: 0.000000\n",
      "Test: epoch: 109 loss: 42.052231 | Acc: 0.947970 | mAP: 0.000000\n",
      "[1.         0.93357709 0.94915254 0.98425197 0.88118812 0.75\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.92966158 0.94069193 0.93973635 0.97052632]\n",
      "Best epoch: 103 | Best acc: 0.950854\n",
      "Train: epoch: 110 loss: 45.624788 | Acc: 0.945418 | mAP: 0.000000\n",
      "Test: epoch: 110 loss: 42.122286 | Acc: 0.949079 | mAP: 0.000000\n",
      "[1.         0.92870201 0.96610169 0.98687664 0.91371994 0.75\n",
      " 1.         1.         1.         0.89430894 1.         1.\n",
      " 1.         1.         0.93762442 0.92668863 0.93785311 0.97263158]\n",
      "Best epoch: 103 | Best acc: 0.950854\n",
      "Train: epoch: 111 loss: 45.702776 | Acc: 0.943199 | mAP: 0.000000\n",
      "Test: epoch: 111 loss: 42.447785 | Acc: 0.946306 | mAP: 0.000000\n",
      "[1.         0.95063985 0.96610169 0.98687664 0.9009901  0.296875\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.93563371 0.93080725 0.94161959 0.97263158]\n",
      "Best epoch: 103 | Best acc: 0.950854\n",
      "Train: epoch: 112 loss: 45.420962 | Acc: 0.944642 | mAP: 0.000000\n",
      "Test: epoch: 112 loss: 42.325309 | Acc: 0.946860 | mAP: 0.000000\n",
      "[1.         0.93357709 0.96610169 0.98687664 0.88401697 0.7421875\n",
      " 1.         1.         1.         0.93495935 1.         1.\n",
      " 1.         1.         0.94359655 0.90939044 0.94161959 0.97052632]\n",
      "Best epoch: 103 | Best acc: 0.950854\n",
      "Train: epoch: 113 loss: 45.688280 | Acc: 0.946528 | mAP: 0.000000\n",
      "Test: epoch: 113 loss: 42.371847 | Acc: 0.946639 | mAP: 0.000000\n",
      "[1.         0.92992078 0.98305085 0.98687664 0.89250354 0.75\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.93497014 0.91762768 0.94161959 0.97473684]\n",
      "Best epoch: 103 | Best acc: 0.950854\n",
      "Train: epoch: 114 loss: 45.661098 | Acc: 0.945196 | mAP: 0.000000\n",
      "Test: epoch: 114 loss: 42.304645 | Acc: 0.949190 | mAP: 0.000000\n",
      "[1.         0.9329677  0.96610169 0.98687664 0.8854314  0.75\n",
      " 1.         1.         1.         0.91869919 1.         1.\n",
      " 1.         1.         0.92899801 0.94398682 0.94161959 0.97473684]\n",
      "Best epoch: 103 | Best acc: 0.950854\n",
      "Train: epoch: 115 loss: 45.510505 | Acc: 0.943532 | mAP: 0.000000\n",
      "Test: epoch: 115 loss: 42.487409 | Acc: 0.947970 | mAP: 0.000000\n",
      "[1.         0.94759293 0.98305085 0.98687664 0.85148515 0.75\n",
      " 1.         1.         1.         0.88617886 1.         1.\n",
      " 1.         1.         0.94094227 0.92421746 0.94161959 0.97052632]\n",
      "Best epoch: 103 | Best acc: 0.950854\n",
      "Train: epoch: 116 loss: 45.528961 | Acc: 0.944087 | mAP: 0.000000\n",
      "Test: epoch: 116 loss: 42.502111 | Acc: 0.947859 | mAP: 0.000000\n",
      "[1.         0.9329677  0.96610169 0.98687664 0.87553041 0.75\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.93231586 0.93822076 0.94161959 0.97052632]\n",
      "Best epoch: 103 | Best acc: 0.950854\n",
      "Train: epoch: 117 loss: 45.900112 | Acc: 0.944864 | mAP: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: epoch: 117 loss: 42.270046 | Acc: 0.947637 | mAP: 0.000000\n",
      "[1.         0.93113955 0.94915254 0.98687664 0.89674682 0.75\n",
      " 1.         1.         1.         0.90243902 1.         1.\n",
      " 1.         1.         0.91506304 0.94810544 0.94161959 0.97473684]\n",
      "Best epoch: 103 | Best acc: 0.950854\n",
      "Train: epoch: 118 loss: 45.519553 | Acc: 0.944642 | mAP: 0.000000\n",
      "Test: epoch: 118 loss: 42.389150 | Acc: 0.949856 | mAP: 0.000000\n",
      "[1.         0.92321755 0.94915254 0.98687664 0.93069307 0.75\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.94293298 0.92092257 0.94161959 0.97263158]\n",
      "Best epoch: 103 | Best acc: 0.950854\n",
      "Train: epoch: 119 loss: 45.672694 | Acc: 0.943976 | mAP: 0.000000\n",
      "Test: epoch: 119 loss: 42.023839 | Acc: 0.947859 | mAP: 0.000000\n",
      "[1.         0.93479586 0.94915254 0.98687664 0.87835926 0.75\n",
      " 1.         1.         1.         0.91869919 1.         1.\n",
      " 1.         1.         0.93430657 0.93080725 0.94161959 0.97263158]\n",
      "Best epoch: 103 | Best acc: 0.950854\n",
      "Train: epoch: 120 loss: 45.617345 | Acc: 0.943643 | mAP: 0.000000\n",
      "Test: epoch: 120 loss: 42.956146 | Acc: 0.948414 | mAP: 0.000000\n",
      "[1.         0.94942108 1.         0.98687664 0.84582744 0.75\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.93762442 0.9291598  0.93785311 0.97473684]\n",
      "Best epoch: 103 | Best acc: 0.950854\n",
      "Train: epoch: 121 loss: 45.504165 | Acc: 0.945529 | mAP: 0.000000\n",
      "Test: epoch: 121 loss: 42.010068 | Acc: 0.948414 | mAP: 0.000000\n",
      "[1.         0.93479586 0.98305085 0.98687664 0.88260255 0.75\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.93165229 0.93410214 0.94161959 0.97473684]\n",
      "Best epoch: 103 | Best acc: 0.950854\n",
      "Train: epoch: 122 loss: 45.503696 | Acc: 0.946417 | mAP: 0.000000\n",
      "Test: epoch: 122 loss: 42.297816 | Acc: 0.946084 | mAP: 0.000000\n",
      "[1.         0.9408897  0.98305085 0.98687664 0.85148515 0.75\n",
      " 1.         1.         1.         0.95934959 1.         1.\n",
      " 1.         1.         0.93828799 0.91515651 0.93973635 0.97263158]\n",
      "Best epoch: 103 | Best acc: 0.950854\n",
      "Train: epoch: 123 loss: 45.578222 | Acc: 0.945751 | mAP: 0.000000\n",
      "Test: epoch: 123 loss: 42.406953 | Acc: 0.947748 | mAP: 0.000000\n",
      "[1.         0.94393662 0.96610169 0.98687664 0.8387553  0.75\n",
      " 1.         1.         1.         0.95934959 1.         1.\n",
      " 1.         1.         0.94160584 0.92751236 0.93973635 0.97263158]\n",
      "Best epoch: 103 | Best acc: 0.950854\n",
      "Train: epoch: 124 loss: 45.234064 | Acc: 0.946639 | mAP: 0.000000\n",
      "Test: epoch: 124 loss: 42.228445 | Acc: 0.947304 | mAP: 0.000000\n",
      "[1.         0.9329677  0.94915254 0.98687664 0.88967468 0.75\n",
      " 1.         1.         1.         0.88617886 1.         1.\n",
      " 1.         1.         0.91705375 0.94645799 0.94161959 0.97473684]\n",
      "Best epoch: 103 | Best acc: 0.950854\n",
      "Train: epoch: 125 loss: 45.456594 | Acc: 0.946639 | mAP: 0.000000\n",
      "Test: epoch: 125 loss: 42.305812 | Acc: 0.947748 | mAP: 0.000000\n",
      "[1.         0.94576478 0.96610169 0.98687664 0.83168317 0.7578125\n",
      " 1.         1.         1.         0.95121951 1.         1.\n",
      " 1.         1.         0.92568016 0.94810544 0.94161959 0.97263158]\n",
      "Best epoch: 103 | Best acc: 0.950854\n",
      "Train: epoch: 126 loss: 45.175664 | Acc: 0.945640 | mAP: 0.000000\n",
      "Test: epoch: 126 loss: 42.113318 | Acc: 0.948303 | mAP: 0.000000\n",
      "[1.         0.93723339 0.98305085 0.98687664 0.87411598 0.734375\n",
      " 1.         1.         1.         0.92682927 1.         1.\n",
      " 1.         1.         0.93895156 0.92668863 0.94161959 0.97263158]\n",
      "Best epoch: 103 | Best acc: 0.950854\n",
      "Train: epoch: 127 loss: 44.834382 | Acc: 0.945529 | mAP: 0.000000\n",
      "Test: epoch: 127 loss: 42.391134 | Acc: 0.948525 | mAP: 0.000000\n",
      "[1.         0.92870201 0.94915254 0.98687664 0.90381895 0.75\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.93497014 0.91927512 0.96233522 0.97473684]\n",
      "Best epoch: 103 | Best acc: 0.950854\n",
      "Train: epoch: 128 loss: 45.302345 | Acc: 0.944087 | mAP: 0.000000\n",
      "Test: epoch: 128 loss: 42.683006 | Acc: 0.950189 | mAP: 0.000000\n",
      "[1.         0.91956124 1.         0.98687664 0.93493635 0.75\n",
      " 1.         1.         1.         0.90243902 1.         1.\n",
      " 1.         1.         0.92899801 0.94151565 0.94161959 0.97263158]\n",
      "Best epoch: 103 | Best acc: 0.950854\n",
      "Train: epoch: 129 loss: 45.176308 | Acc: 0.946306 | mAP: 0.000000\n",
      "Test: epoch: 129 loss: 42.156810 | Acc: 0.948081 | mAP: 0.000000\n",
      "[1.         0.94820232 0.96610169 0.98687664 0.84582744 0.75\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.9402787  0.92586491 0.94161959 0.97263158]\n",
      "Best epoch: 103 | Best acc: 0.950854\n",
      "Train: epoch: 130 loss: 45.103575 | Acc: 0.943976 | mAP: 0.000000\n",
      "Test: epoch: 130 loss: 42.472883 | Acc: 0.948192 | mAP: 0.000000\n",
      "[1.         0.93723339 0.94915254 0.98687664 0.87128713 0.75\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.93430657 0.93492586 0.94161959 0.97263158]\n",
      "Best epoch: 103 | Best acc: 0.950854\n",
      "Train: epoch: 131 loss: 45.536383 | Acc: 0.944642 | mAP: 0.000000\n",
      "Test: epoch: 131 loss: 41.921522 | Acc: 0.949301 | mAP: 0.000000\n",
      "[1.         0.93357709 0.94915254 0.98687664 0.88967468 0.75\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.92833444 0.94481054 0.94161959 0.97263158]\n",
      "Best epoch: 103 | Best acc: 0.950854\n",
      "Train: epoch: 132 loss: 45.023722 | Acc: 0.946195 | mAP: 0.000000\n",
      "Test: epoch: 132 loss: 41.926325 | Acc: 0.948303 | mAP: 0.000000\n",
      "[1.         0.93479586 0.96610169 0.98687664 0.87553041 0.75\n",
      " 1.         1.         1.         0.90243902 1.         1.\n",
      " 1.         1.         0.93430657 0.93739703 0.94161959 0.97052632]\n",
      "Best epoch: 103 | Best acc: 0.950854\n",
      "Train: epoch: 133 loss: 44.867022 | Acc: 0.945418 | mAP: 0.000000\n",
      "Test: epoch: 133 loss: 42.262299 | Acc: 0.947637 | mAP: 0.000000\n",
      "[1.         0.93479586 0.96610169 0.98687664 0.87411598 0.75\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.933643   0.9324547  0.94161959 0.97263158]\n",
      "Best epoch: 103 | Best acc: 0.950854\n",
      "Train: epoch: 134 loss: 45.153192 | Acc: 0.945418 | mAP: 0.000000\n",
      "Test: epoch: 134 loss: 42.510229 | Acc: 0.948081 | mAP: 0.000000\n",
      "[1.         0.9213894  0.96610169 0.98687664 0.91796322 0.75\n",
      " 1.         1.         1.         0.95934959 1.         1.\n",
      " 1.         1.         0.9402787  0.91433278 0.94161959 0.97473684]\n",
      "Best epoch: 103 | Best acc: 0.950854\n",
      "Train: epoch: 135 loss: 44.921683 | Acc: 0.946084 | mAP: 0.000000\n",
      "Test: epoch: 135 loss: 42.078599 | Acc: 0.946528 | mAP: 0.000000\n",
      "[1.         0.93601463 1.         0.98687664 0.86280057 0.75\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.93629728 0.92421746 0.94161959 0.97263158]\n",
      "Best epoch: 103 | Best acc: 0.950854\n",
      "Train: epoch: 136 loss: 44.900865 | Acc: 0.945418 | mAP: 0.000000\n",
      "Test: epoch: 136 loss: 42.399097 | Acc: 0.945862 | mAP: 0.000000\n",
      "[1.         0.93418647 1.         0.98687664 0.87694484 0.75\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.9402787  0.907743   0.94161959 0.97473684]\n",
      "Best epoch: 103 | Best acc: 0.950854\n",
      "Train: epoch: 137 loss: 44.942771 | Acc: 0.944420 | mAP: 0.000000\n",
      "Test: epoch: 137 loss: 42.513691 | Acc: 0.948081 | mAP: 0.000000\n",
      "[1.         0.94637416 0.98305085 0.98687664 0.8330976  0.75\n",
      " 1.         1.         1.         0.95934959 1.         1.\n",
      " 1.         1.         0.94226941 0.92668863 0.94161959 0.97473684]\n",
      "Best epoch: 103 | Best acc: 0.950854\n",
      "Train: epoch: 138 loss: 44.957772 | Acc: 0.945862 | mAP: 0.000000\n",
      "Test: epoch: 138 loss: 42.092841 | Acc: 0.948968 | mAP: 0.000000\n",
      "[1.         0.93113955 0.94915254 0.98687664 0.90523338 0.75\n",
      " 1.         1.         1.         0.90243902 1.         1.\n",
      " 1.         1.         0.92435302 0.9431631  0.94161959 0.97052632]\n",
      "Best epoch: 103 | Best acc: 0.950854\n",
      "Train: epoch: 139 loss: 44.994507 | Acc: 0.945307 | mAP: 0.000000\n",
      "Test: epoch: 139 loss: 42.208828 | Acc: 0.950078 | mAP: 0.000000\n",
      "[1.         0.92078001 1.         0.98687664 0.93493635 0.75\n",
      " 1.         1.         1.         0.89430894 1.         1.\n",
      " 1.         1.         0.93961513 0.92751236 0.94161959 0.97052632]\n",
      "Best epoch: 103 | Best acc: 0.950854\n",
      "Train: epoch: 140 loss: 44.922138 | Acc: 0.946084 | mAP: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: epoch: 140 loss: 42.182461 | Acc: 0.947415 | mAP: 0.000000\n",
      "[1.         0.93235832 1.         0.98687664 0.89250354 0.75\n",
      " 1.         1.         1.         0.80487805 1.         1.\n",
      " 1.         1.         0.93297943 0.9324547  0.94161959 0.97473684]\n",
      "Best epoch: 103 | Best acc: 0.950854\n",
      "Train: epoch: 141 loss: 45.079163 | Acc: 0.946528 | mAP: 0.000000\n",
      "Test: epoch: 141 loss: 42.138873 | Acc: 0.949745 | mAP: 0.000000\n",
      "[1.         0.9213894  0.96610169 0.98687664 0.93635078 0.75\n",
      " 1.         1.         1.         0.88617886 1.         1.\n",
      " 1.         1.         0.933643   0.93163097 0.94161959 0.97473684]\n",
      "Best epoch: 103 | Best acc: 0.950854\n",
      "Train: epoch: 142 loss: 44.908445 | Acc: 0.945085 | mAP: 0.000000\n",
      "Test: epoch: 142 loss: 41.796982 | Acc: 0.947526 | mAP: 0.000000\n",
      "[1.         0.93418647 0.98305085 0.98687664 0.87270156 0.75\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.93231586 0.93327842 0.94161959 0.97473684]\n",
      "Best epoch: 103 | Best acc: 0.950854\n",
      "Train: epoch: 143 loss: 44.585896 | Acc: 0.945973 | mAP: 0.000000\n",
      "Test: epoch: 143 loss: 42.217664 | Acc: 0.949190 | mAP: 0.000000\n",
      "[1.         0.93053016 0.96610169 0.98687664 0.92362093 0.7421875\n",
      " 1.         1.         1.         0.80487805 1.         1.\n",
      " 1.         1.         0.92634373 0.94069193 0.94161959 0.97473684]\n",
      "Best epoch: 103 | Best acc: 0.950854\n",
      "Train: epoch: 144 loss: 44.807110 | Acc: 0.946528 | mAP: 0.000000\n",
      "Test: epoch: 144 loss: 41.942836 | Acc: 0.949523 | mAP: 0.000000\n",
      "[1.         0.92565509 0.96610169 0.98687664 0.92503536 0.75\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.94492369 0.91515651 0.94161959 0.97263158]\n",
      "Best epoch: 103 | Best acc: 0.950854\n",
      "Train: epoch: 145 loss: 45.051846 | Acc: 0.945418 | mAP: 0.000000\n",
      "Test: epoch: 145 loss: 42.486651 | Acc: 0.945640 | mAP: 0.000000\n",
      "[1.         0.93540524 0.94915254 0.98687664 0.86421499 0.71875\n",
      " 1.         1.         1.         0.91869919 1.         1.\n",
      " 1.         1.         0.93297943 0.92504119 0.94538606 0.97263158]\n",
      "Best epoch: 103 | Best acc: 0.950854\n",
      "Train: epoch: 146 loss: 44.819730 | Acc: 0.945751 | mAP: 0.000000\n",
      "Test: epoch: 146 loss: 42.693051 | Acc: 0.946528 | mAP: 0.000000\n",
      "[1.         0.94820232 0.94915254 0.98425197 0.85148515 0.75\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.94293298 0.90444811 0.95103578 0.97473684]\n",
      "Best epoch: 103 | Best acc: 0.950854\n",
      "Train: epoch: 147 loss: 44.889541 | Acc: 0.946084 | mAP: 0.000000\n",
      "Test: epoch: 147 loss: 42.256329 | Acc: 0.948414 | mAP: 0.000000\n",
      "[1.         0.9293114  0.98305085 0.98687664 0.92503536 0.75\n",
      " 1.         1.         1.         0.90243902 1.         1.\n",
      " 1.         1.         0.93430657 0.91433278 0.94161959 0.97473684]\n",
      "Best epoch: 103 | Best acc: 0.950854\n",
      "Train: epoch: 148 loss: 44.726526 | Acc: 0.946195 | mAP: 0.000000\n",
      "Test: epoch: 148 loss: 41.918794 | Acc: 0.947526 | mAP: 0.000000\n",
      "[1.         0.93784278 0.96610169 0.98687664 0.86704385 0.75\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.93497014 0.9291598  0.94161959 0.97473684]\n",
      "Best epoch: 103 | Best acc: 0.950854\n",
      "Train: epoch: 149 loss: 44.989337 | Acc: 0.943976 | mAP: 0.000000\n",
      "Test: epoch: 149 loss: 41.990129 | Acc: 0.949745 | mAP: 0.000000\n",
      "[1.         0.92565509 0.98305085 0.98687664 0.93069307 0.75\n",
      " 1.         1.         1.         0.91056911 1.         1.\n",
      " 1.         1.         0.93497014 0.92421746 0.94161959 0.97473684]\n",
      "Best epoch: 103 | Best acc: 0.950854\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "\n",
    "def seed_everything(seed=27):\n",
    "    '''\n",
    "    Set random seed for reproducible experiments\n",
    "    Inputs: seed number \n",
    "    '''\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "     \n",
    "    # Set random seed\n",
    "    seed_everything()  \n",
    "    \n",
    "    # Device Count\n",
    "    num_gpu = torch.cuda.device_count()\n",
    "    \n",
    "    # hyperparameters\n",
    "    bs = 32\n",
    "    epochs = 150\n",
    "    lr = 0.00001\n",
    "    \n",
    "    checkpoint_dir = 'checkpoints/v4/simple/'\n",
    "    \n",
    "    # train and test dataloader\n",
    "    train_seq = [2, 3, 4, 6, 7, 9, 10, 11, 12, 14, 15]\n",
    "    val_seq = [1, 5, 16]\n",
    "    folder_head = 'dataset/instruments18/seq_'\n",
    "    folder_tail = '/vqa/simple/*.txt'\n",
    "\n",
    "    labels = ['kidney',\n",
    "          'Idle', 'Grasping', 'Retraction', 'Tissue_Manipulation',\n",
    "          'Tool_Manipulation', 'Cutting', 'Cauterization', 'Suction', \n",
    "          'Looping', 'Suturing', 'Clipping', 'Staple', 'Ultrasound_Sensing',\n",
    "          'left-top', 'right-top', 'left-bottom', 'right-bottom']\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "                transforms.Resize((300,256)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "                ])\n",
    "\n",
    "    # train_dataset\n",
    "    train_dataset = SurgicalVQADataset(train_seq, folder_head, folder_tail, labels, transform=transform)\n",
    "    train_dataloader = DataLoader(dataset=train_dataset, batch_size= bs, shuffle=True)\n",
    "\n",
    "    # Val_dataset\n",
    "    val_dataset = SurgicalVQADataset(val_seq, folder_head, folder_tail, labels, transform=transform)\n",
    "    val_dataloader = DataLoader(dataset=val_dataset, batch_size= bs, shuffle=False)\n",
    "    \n",
    "    # model\n",
    "    model = Surgical_VQA(num_classes=len(labels)).cuda()\n",
    "    \n",
    "    best_epoch = [0]\n",
    "    best_results = [0.0]\n",
    "    \n",
    "    for epoch in range(1, epochs):\n",
    "        train_model(epoch, model, train_dataloader, lr)\n",
    "        test_acc, test_c_acc, mAP = test_model(epoch, model, train_dataloader)\n",
    "    \n",
    "        if test_acc >= best_results[0]:\n",
    "            best_results[0] = test_acc\n",
    "            best_epoch[0] = epoch\n",
    "        \n",
    "        print('Best epoch: %d | Best acc: %.6f' %(best_epoch[0], best_results[0]))\n",
    "        checkpoint = {'lr': lr, 'b_s': bs, 'state_dict': model.state_dict() }\n",
    "        save_name = \"checkpoint_\" + str(epoch) + '_epoch.pth'\n",
    "        \n",
    "        torch.save(checkpoint, os.path.join(checkpoint_dir, save_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6779af06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1c3288",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
